{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 2 Regression and Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/mlip/blob/master/d2/Regression_and_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfI8r7bYXLU2",
        "colab_type": "text"
      },
      "source": [
        "## Regression\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvvSdefNLnNG",
        "colab_type": "text"
      },
      "source": [
        "###1. Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkH1zwGwZBH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supplementary functions\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# generate points to plot\n",
        "def generate_points_linear():\n",
        "  x = np.linspace(1, 100, num=100)\n",
        "  np.random.shuffle(x)\n",
        "  pick = x[:50]\n",
        "  X, X_test = pick[:30, np.newaxis], pick[20:, np.newaxis]\n",
        "  return X, X_test\n",
        "\n",
        "# linead function \n",
        "def lin_fun(x):\n",
        "  # add noise \n",
        "  noise = np.random.normal(0,15,x.shape[0])\n",
        "  noise = noise[:, np.newaxis]\n",
        " \n",
        "  y = -3 * x + 2 + noise\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCp_0Cnf_Jpa",
        "colab_type": "text"
      },
      "source": [
        "We train a line regression model to fit this data using scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AidH44Ww-6jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset\n",
        "X, X_test = generate_points_linear()\n",
        "y, y_test = lin_fun(X), lin_fun(X_test)\n",
        "\n",
        "#visualizing data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo', label='training')\n",
        "plt.plot(X_test, y_test, 'r^', label='testing')\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linear_regressor = LinearRegression().fit(X, y)\n",
        "X_test.sort(axis=0)\n",
        "y_pred = linear_regressor.predict(X_test) \n",
        "plt.plot(X_test, y_pred, 'r--', label='prediction')\n",
        "plt.legend()\n",
        "\n",
        "# print coefficients\n",
        "print('Coefficient =', linear_regressor.coef_[0], 'Intercept =', linear_regressor.intercept_ )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wATaSlC8DgTB",
        "colab_type": "text"
      },
      "source": [
        "###2. Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4j5hllPDqR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate points to plot\n",
        "def generate_points_poly():\n",
        "  x = np.linspace(1, 10, num=1000)\n",
        "  np.random.shuffle(x)\n",
        "  pick = x[:30]\n",
        "  X, X_test = pick[:20, np.newaxis], pick[10:, np.newaxis]\n",
        "  return X, X_test\n",
        "\n",
        "\n",
        "def poly_fun(x):\n",
        "  # add noise \n",
        "  noise = np.random.normal(0,15,x.shape[0])\n",
        "  noise = noise[:, np.newaxis]\n",
        " \n",
        "  y = x * np.sin(x) \n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcs5wRnRD5BY",
        "colab_type": "text"
      },
      "source": [
        "We use a linear regression model with polynomial features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN6viGarD3-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset\n",
        "X, X_test = generate_points_poly()\n",
        "y, y_test = poly_fun(X), poly_fun(X_test)\n",
        "\n",
        "#visualizing data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo', label = 'training')\n",
        "plt.plot(X_test, y_test, 'r^', label = 'testing')\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# # pipeline will first transform X to polynomial form and then apply linear regression\n",
        "# # experiment with degree value for a better fit\n",
        "degree = 1\n",
        "\n",
        "pipeline = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "poly_regressor = pipeline.fit(X, y)\n",
        "\n",
        "X_test.sort(axis=0)\n",
        "y_pred = poly_regressor.predict(X_test)\n",
        "plt.plot(X_test, y_pred, 'r--', label = 'prediction')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ZUAQ8jLSlv",
        "colab_type": "text"
      },
      "source": [
        "### 3. Problem 1 \n",
        "For this problem we you be working on the [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset), where you will predict the disease progression based on given features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awFiG5d8m8Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "def read_data():\n",
        "  diabetes = datasets.load_diabetes()  \n",
        "  features = diabetes['data']\n",
        "  output = diabetes['target']\n",
        "  \n",
        "  X, y = features[:-50, :], output[:-50]\n",
        "  X_test, y_test = features[-50:, :], output[-50:]\n",
        "  \n",
        "  return X, y, X_test, y_test\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bSpqPdeqrWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data\n",
        "X, y, X_test, y_test = read_data()\n",
        "\n",
        "\n",
        "# TODO: Implement regression model\n",
        "def predict(X, y, X_test):\n",
        "  # ...\n",
        "  # ...\n",
        "  # ...\n",
        "  return None\n",
        "\n",
        "\n",
        "y_pred = predict(X, y, X_test)\n",
        "\n",
        "\n",
        "# evaluate performance\n",
        "from sklearn.metrics import mean_squared_error\n",
        "error = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error = ', error)\n",
        "\n",
        "pick = np.random.randint(0,y_test.shape[0], size=10)\n",
        "print('\\nTrue value\\tPredicted value')\n",
        "for i in pick:\n",
        "  print(y_test[i],'\\t\\t', y_pred[i])\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MHmQq9LBL2",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8npZ48ijYVE",
        "colab_type": "text"
      },
      "source": [
        "![Precision Recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png)\n",
        "![alt text](https://msdnshared.blob.core.windows.net/media/MSDNBlogsFS/prod.evol.blogs.msdn.com/CommunityServer.Blogs.Components.WeblogFiles/00/00/01/57/11/metablogapi/0116.image_thumb_3213B628.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8BW1u8FLF6s",
        "colab_type": "text"
      },
      "source": [
        "### 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPAQCpJTLR0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def generate_points():\n",
        "  X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=6)  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def visualize(X_train, y_train, X_test, y_test, classifier):\n",
        "  cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
        "  cm = plt.cm.RdBu\n",
        "  h = .02\n",
        " \n",
        "  X = np.concatenate((X_train, X_test))\n",
        "  y = np.concatenate((y_train, y_test))\n",
        "  \n",
        "  x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "  y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "  \n",
        "  if hasattr(clf, \"decision_function\"):\n",
        "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "  else:\n",
        "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "  \n",
        "  # Put the result into a color plot\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "   \n",
        "  # Plot the training points\n",
        "  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
        "\n",
        "  # Plot the testing points\n",
        "  plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k')\n",
        "  \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciSRt44BNsFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X, y, X_test, y_test = generate_points()\n",
        "\n",
        "# classify\n",
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# visualize\n",
        "visualize(X, y, X_test, y_test, clf)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csOfKI5nRzYy",
        "colab_type": "text"
      },
      "source": [
        "### 2. SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU1HSEKWR5FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "from sklearn.datasets.samples_generator import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def generate_points():\n",
        "  X, y = make_moons(n_samples=100, shuffle=True, noise=0.1, random_state=6)  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def visualize(X_train, y_train, X_test, y_test, classifier):\n",
        "  cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
        "  cm = plt.cm.RdBu\n",
        "  h = .02\n",
        " \n",
        "  X = np.concatenate((X_train, X_test))\n",
        "  y = np.concatenate((y_train, y_test))\n",
        "  \n",
        "  x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "  y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "  \n",
        "  if hasattr(classifier, \"decision_function\"):\n",
        "    Z = classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "  else:\n",
        "    Z = classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "  \n",
        "  # Put the result into a color plot\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "   \n",
        "  # Plot the training points\n",
        "  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
        "\n",
        "  # Plot the testing points\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao0nZBL2TD7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X, y, X_test, y_test = generate_points()\n",
        "\n",
        "# classify\n",
        "\n",
        "\n",
        "# Kernel can be ‘linear’, ‘rbf’ or ‘sigmoid’\n",
        "# Vary gamma from 0.001 to 5\n",
        "\n",
        "kernel = 'Linear'\n",
        "clf = SVC(gamma=0.001).fit(X, y)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# visualize\n",
        "visualize(X, y, X_test, y_test, clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-msotwkVWfR",
        "colab_type": "text"
      },
      "source": [
        "### 3. Problem 2 \n",
        "For this problem we will use the [Iris Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html), which contains the features of Iris flowers of three related species."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah-sWV6bVVTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def read_data():\n",
        "  diabetes = datasets.load_iris()  \n",
        "  features = diabetes['data']\n",
        "  output = diabetes['target']\n",
        "  \n",
        "  splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
        "  splitter.get_n_splits(features, output)\n",
        "  \n",
        "  train_index, test_index = next(splitter.split(features, output))\n",
        "  \n",
        "  X, y = features[train_index, :], output[train_index]\n",
        "  X_test, y_test = features[test_index, :], output[test_index]\n",
        "  \n",
        "  return X, y, X_test, y_test\n",
        "\n",
        "\n",
        "def visualize(X_train, y_train, X_test, y_test, classifier):\n",
        "  X = np.concatenate((X_train, X_test))\n",
        "  y = np.concatenate((y_train, y_test))\n",
        "  \n",
        "  X_embedded = TSNE(n_components=2).fit_transform(X)\n",
        "  X_train_embedded, X_test_embedded = X_embedded[:X_train.shape[0]], X_embedded[X_train.shape[0]:]\n",
        "  \n",
        "  cm_bright = ListedColormap(['#FF0000', '#0000FF', '#00FF00'])\n",
        "  cm = plt.cm.RdBu\n",
        "  h = .02\n",
        "  \n",
        "  \n",
        "  # Plot the training points\n",
        "  plt.scatter(X_train_embedded[:, 0], X_train_embedded[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
        "\n",
        "  # Plot the testing points\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  plt.scatter(X_test_embedded[:, 0], X_test_embedded[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2ptbcFmZtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - Implement the classifier by yourself\n",
        "# Step -1 Import libraries (refer libraries imported in above example)\n",
        "\n",
        "\n",
        "\n",
        "# Step -2 Read data (call the function in helper code section)\n",
        "\n",
        "\n",
        "\n",
        "# Step -3 Classify (use a classifier of your choise and vary the parameters of the classifier)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step -4 Print accuracy and optionally visualize (using helper code)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNjKzHrHybU2",
        "colab_type": "text"
      },
      "source": [
        "# Additional Problems\n",
        "\n",
        "Only solve after all basic problems are done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bneyf1cybO6",
        "colab_type": "text"
      },
      "source": [
        "### 1. Regression\n",
        "For this problem you will be required the predict the [energy requirement](https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction)  of a building  based on the observations of a milti-sensor device. Use the helper code to read data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtZrJqI0P2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_time_features(x):\n",
        "\treturn [x.hour, x.minute]\n",
        "\n",
        "def str_to_float(x):\n",
        "  x = x.decode(\"utf-8\")\n",
        "  x = x.replace('\\\"', '')\n",
        "  return float(x)\n",
        "\n",
        "def read_data():\n",
        "  cols = range(27)\n",
        "  url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv'\n",
        "  \n",
        "  \n",
        "  converter_map = {0: lambda x: datetime.strptime(x.decode(\"utf-8\"), \"\\\"%Y-%m-%d %H:%M:%S\\\"\")}\n",
        "  for i in range(1, 27):\n",
        "    converter_map[i] = lambda x: str_to_float(x)\n",
        "  \n",
        "  data = np.loadtxt(url, delimiter=\",\", skiprows=1,  usecols=cols, dtype=object, \n",
        "                     converters=converter_map)\n",
        "  \n",
        "  mapped = np.array(list(map(get_time_features, data[:,0])))\n",
        "  X = np.concatenate((mapped, data[:,2:27]), axis=1)\n",
        "  y = data[:,1]\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def evaulate(y_test, y_pred):\n",
        "  error = mean_squared_error(y_test, y_pred)\n",
        "  print('Mean Squared Error = ', error)\n",
        "\n",
        "  pick = np.random.randint(0,y_test.shape[0], size=10)\n",
        "  print('\\nTrue value\\tPredicted value')\n",
        "  for i in pick:\n",
        "    print(y_test[i],'\\t\\t', y_pred[i])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-qrIW309C4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - Implement the regression problem\n",
        "# use read_data() and evaluate() functions from the helper code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lduvsRsLpjb",
        "colab_type": "text"
      },
      "source": [
        "### 2. Classification\n",
        "For this problem you will be working on the [NIST](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset, where you have to train a ML classifier to recognize hand written gicits \\[0-9\\]. Use the functions in the helper code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMFnC79TLoyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper code\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def read_data():\n",
        "  digits = datasets.load_digits()  \n",
        "  features = digits['data']\n",
        "  output = digits['target']\n",
        "  images = digits['images']\n",
        "\n",
        "  splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
        "  splitter.get_n_splits(features, output)\n",
        "  \n",
        "  train_index, test_index = next(splitter.split(features, output))\n",
        "  \n",
        "  X, y = features[train_index, :], output[train_index]\n",
        "  X_test, y_test = features[test_index, :], output[test_index]\n",
        "  \n",
        "  return X, y, X_test, y_test\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, y_pred):\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  \n",
        "  pick = np.random.randint(0,y_test.shape[0], size=25)\n",
        "  for index in range(len(pick)):\n",
        "    prediction = y_pred[pick[index]] \n",
        "    image = np.reshape(X_test[pick[index]], (8, 8))\n",
        "    \n",
        "    pos = 5 * (2 * (index // 5) + 1) + (index % 5) + 1\n",
        "      \n",
        "    plt.subplot(10, 5, pos)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Prediction: %i' % prediction)\n",
        "  \n",
        "  plt.show()\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIVLdYQkXDFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - Implement the classification problem\n",
        "# use read_data() and evaluate() functions from the helper code"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}